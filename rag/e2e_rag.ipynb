{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "606986be-fd43-4b0f-b69b-02250e57e4b0",
   "metadata": {},
   "source": [
    "### Necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae9d6495-af97-405d-b4d6-63b322cb82d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-29 18:05:32.654999: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-11-29 18:05:33.872397: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "!pip install -q -U torch datasets transformers\n",
    "!pip install -q accelerate==0.21.0 peft==0.4.0 bitsandbytes==0.40.2 trl==0.4.7\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacdda41-708b-4af8-88a9-5056cbd08bf4",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "505ca9a3-8c27-442e-bca6-154a65186d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    ")\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, PeftModel\n",
    "\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.document_transformers import Html2TextTransformer\n",
    "from langchain.document_loaders import AsyncChromiumLoader\n",
    "\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180f8d4e-a8bf-4389-b046-9827b310a3b3",
   "metadata": {},
   "source": [
    "### Load quantized Mistal 7B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80f94e97-7e58-4253-9376-73af6f36e139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Your GPU supports bfloat16: accelerate training with bf16=True\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc1933bc4f504546883a1d69f82aeb46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable model parameters: 262410240\n",
      "all model parameters: 3752071168\n",
      "percentage of trainable model parameters: 6.99%\n"
     ]
    }
   ],
   "source": [
    "#################################################################\n",
    "# Tokenizer\n",
    "#################################################################\n",
    "\n",
    "model_name='mistralai/Mistral-7B-Instruct-v0.1'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "#################################################################\n",
    "# bitsandbytes parameters\n",
    "#################################################################\n",
    "\n",
    "# Activate 4-bit precision base model loading\n",
    "use_4bit = True\n",
    "\n",
    "# Compute dtype for 4-bit base models\n",
    "bnb_4bit_compute_dtype = \"float16\"\n",
    "\n",
    "# Quantization type (fp4 or nf4)\n",
    "bnb_4bit_quant_type = \"nf4\"\n",
    "\n",
    "# Activate nested quantization for 4-bit base models (double quantization)\n",
    "use_nested_quant = False\n",
    "\n",
    "#################################################################\n",
    "# Set up quantization config\n",
    "#################################################################\n",
    "compute_dtype = getattr(torch, bnb_4bit_compute_dtype)\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=use_4bit,\n",
    "    bnb_4bit_quant_type=bnb_4bit_quant_type,\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    "    bnb_4bit_use_double_quant=use_nested_quant,\n",
    ")\n",
    "\n",
    "# Check GPU compatibility with bfloat16\n",
    "if compute_dtype == torch.float16 and use_4bit:\n",
    "    major, _ = torch.cuda.get_device_capability()\n",
    "    if major >= 8:\n",
    "        print(\"=\" * 80)\n",
    "        print(\"Your GPU supports bfloat16: accelerate training with bf16=True\")\n",
    "        print(\"=\" * 80)\n",
    "\n",
    "#################################################################\n",
    "# Load pre-trained config\n",
    "#################################################################\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fb199a-a537-4bd7-9888-d43a84c8ff69",
   "metadata": {},
   "source": [
    "### Count number of trainable parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d2a86e-69e8-496f-b388-853168537c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_number_of_trainable_model_parameters(model):\n",
    "    trainable_model_params = 0\n",
    "    all_model_params = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_model_params += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_model_params += param.numel()\n",
    "    return f\"trainable model parameters: {trainable_model_params}\\nall model parameters: {all_model_params}\\npercentage of trainable model parameters: {100 * trainable_model_params / all_model_params:.2f}%\"\n",
    "\n",
    "print(print_number_of_trainable_model_parameters(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a38c760-f5c8-49c6-9c0c-80719557fee5",
   "metadata": {},
   "source": [
    "### Build Mistral text generation pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c613429-9e6c-4a1e-bc9c-579eb152434b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_generation_pipeline = transformers.pipeline(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    task=\"text-generation\",\n",
    "    temperature=0.2,\n",
    "    repetition_penalty=1.1,\n",
    "    return_full_text=True,\n",
    "    max_new_tokens=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c859dd05-9114-42f1-81f2-52a28b7efdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mistral_llm = HuggingFacePipeline(pipeline=text_generation_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a07789-78f5-498c-987b-9ed3eb459fe6",
   "metadata": {},
   "source": [
    "### Load and chunk documents. Load chunked documents into FAISS index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79a2e41f-aee3-47ff-92a1-74970f3b313a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Articles to index\n",
    "articles = [\"https://www.fantasypros.com/2023/11/rival-fantasy-nfl-week-10/\",\n",
    "            \"https://www.fantasypros.com/2023/11/5-stats-to-know-before-setting-your-fantasy-lineup-week-10/\",\n",
    "            \"https://www.fantasypros.com/2023/11/nfl-week-10-sleeper-picks-player-predictions-2023/\",\n",
    "            \"https://www.fantasypros.com/2023/11/nfl-dfs-week-10-stacking-advice-picks-2023-fantasy-football/\",\n",
    "            \"https://www.fantasypros.com/2023/11/players-to-buy-low-sell-high-trade-advice-2023-fantasy-football/\"]\n",
    "\n",
    "# Scrapes the blogs above\n",
    "loader = AsyncChromiumLoader(articles)\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65680d19-1fc3-4a2d-8901-58c6e844a7b3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 146, which is longer than the specified 100\n",
      "Created a chunk of size 4148, which is longer than the specified 100\n",
      "Created a chunk of size 131, which is longer than the specified 100\n",
      "Created a chunk of size 230, which is longer than the specified 100\n",
      "Created a chunk of size 500, which is longer than the specified 100\n",
      "Created a chunk of size 207, which is longer than the specified 100\n",
      "Created a chunk of size 365, which is longer than the specified 100\n",
      "Created a chunk of size 312, which is longer than the specified 100\n",
      "Created a chunk of size 515, which is longer than the specified 100\n",
      "Created a chunk of size 584, which is longer than the specified 100\n",
      "Created a chunk of size 1119, which is longer than the specified 100\n",
      "Created a chunk of size 257, which is longer than the specified 100\n",
      "Created a chunk of size 103, which is longer than the specified 100\n",
      "Created a chunk of size 136, which is longer than the specified 100\n",
      "Created a chunk of size 230, which is longer than the specified 100\n",
      "Created a chunk of size 105, which is longer than the specified 100\n",
      "Created a chunk of size 134, which is longer than the specified 100\n",
      "Created a chunk of size 224, which is longer than the specified 100\n",
      "Created a chunk of size 120, which is longer than the specified 100\n",
      "Created a chunk of size 103, which is longer than the specified 100\n",
      "Created a chunk of size 232, which is longer than the specified 100\n",
      "Created a chunk of size 118, which is longer than the specified 100\n",
      "Created a chunk of size 142, which is longer than the specified 100\n",
      "Created a chunk of size 293, which is longer than the specified 100\n",
      "Created a chunk of size 146, which is longer than the specified 100\n",
      "Created a chunk of size 4148, which is longer than the specified 100\n",
      "Created a chunk of size 567, which is longer than the specified 100\n",
      "Created a chunk of size 316, which is longer than the specified 100\n",
      "Created a chunk of size 136, which is longer than the specified 100\n",
      "Created a chunk of size 249, which is longer than the specified 100\n",
      "Created a chunk of size 113, which is longer than the specified 100\n",
      "Created a chunk of size 449, which is longer than the specified 100\n",
      "Created a chunk of size 137, which is longer than the specified 100\n",
      "Created a chunk of size 201, which is longer than the specified 100\n",
      "Created a chunk of size 132, which is longer than the specified 100\n",
      "Created a chunk of size 479, which is longer than the specified 100\n",
      "Created a chunk of size 216, which is longer than the specified 100\n",
      "Created a chunk of size 138, which is longer than the specified 100\n",
      "Created a chunk of size 172, which is longer than the specified 100\n",
      "Created a chunk of size 183, which is longer than the specified 100\n",
      "Created a chunk of size 140, which is longer than the specified 100\n",
      "Created a chunk of size 180, which is longer than the specified 100\n",
      "Created a chunk of size 118, which is longer than the specified 100\n",
      "Created a chunk of size 114, which is longer than the specified 100\n",
      "Created a chunk of size 194, which is longer than the specified 100\n",
      "Created a chunk of size 533, which is longer than the specified 100\n",
      "Created a chunk of size 446, which is longer than the specified 100\n",
      "Created a chunk of size 141, which is longer than the specified 100\n",
      "Created a chunk of size 120, which is longer than the specified 100\n",
      "Created a chunk of size 317, which is longer than the specified 100\n",
      "Created a chunk of size 142, which is longer than the specified 100\n",
      "Created a chunk of size 120, which is longer than the specified 100\n",
      "Created a chunk of size 103, which is longer than the specified 100\n",
      "Created a chunk of size 232, which is longer than the specified 100\n",
      "Created a chunk of size 118, which is longer than the specified 100\n",
      "Created a chunk of size 142, which is longer than the specified 100\n",
      "Created a chunk of size 293, which is longer than the specified 100\n",
      "Created a chunk of size 146, which is longer than the specified 100\n",
      "Created a chunk of size 4148, which is longer than the specified 100\n",
      "Created a chunk of size 450, which is longer than the specified 100\n",
      "Created a chunk of size 125, which is longer than the specified 100\n",
      "Created a chunk of size 133, which is longer than the specified 100\n",
      "Created a chunk of size 462, which is longer than the specified 100\n",
      "Created a chunk of size 178, which is longer than the specified 100\n",
      "Created a chunk of size 469, which is longer than the specified 100\n",
      "Created a chunk of size 432, which is longer than the specified 100\n",
      "Created a chunk of size 380, which is longer than the specified 100\n",
      "Created a chunk of size 105, which is longer than the specified 100\n",
      "Created a chunk of size 134, which is longer than the specified 100\n",
      "Created a chunk of size 132, which is longer than the specified 100\n",
      "Created a chunk of size 120, which is longer than the specified 100\n",
      "Created a chunk of size 103, which is longer than the specified 100\n",
      "Created a chunk of size 232, which is longer than the specified 100\n",
      "Created a chunk of size 118, which is longer than the specified 100\n",
      "Created a chunk of size 142, which is longer than the specified 100\n",
      "Created a chunk of size 293, which is longer than the specified 100\n",
      "Created a chunk of size 146, which is longer than the specified 100\n",
      "Created a chunk of size 4148, which is longer than the specified 100\n",
      "Created a chunk of size 178, which is longer than the specified 100\n",
      "Created a chunk of size 422, which is longer than the specified 100\n",
      "Created a chunk of size 282, which is longer than the specified 100\n",
      "Created a chunk of size 498, which is longer than the specified 100\n",
      "Created a chunk of size 164, which is longer than the specified 100\n",
      "Created a chunk of size 413, which is longer than the specified 100\n",
      "Created a chunk of size 242, which is longer than the specified 100\n",
      "Created a chunk of size 203, which is longer than the specified 100\n",
      "Created a chunk of size 456, which is longer than the specified 100\n",
      "Created a chunk of size 404, which is longer than the specified 100\n",
      "Created a chunk of size 145, which is longer than the specified 100\n",
      "Created a chunk of size 127, which is longer than the specified 100\n",
      "Created a chunk of size 232, which is longer than the specified 100\n",
      "Created a chunk of size 139, which is longer than the specified 100\n",
      "Created a chunk of size 221, which is longer than the specified 100\n",
      "Created a chunk of size 154, which is longer than the specified 100\n",
      "Created a chunk of size 121, which is longer than the specified 100\n",
      "Created a chunk of size 380, which is longer than the specified 100\n",
      "Created a chunk of size 234, which is longer than the specified 100\n",
      "Created a chunk of size 123, which is longer than the specified 100\n",
      "Created a chunk of size 230, which is longer than the specified 100\n",
      "Created a chunk of size 346, which is longer than the specified 100\n",
      "Created a chunk of size 142, which is longer than the specified 100\n",
      "Created a chunk of size 120, which is longer than the specified 100\n",
      "Created a chunk of size 103, which is longer than the specified 100\n",
      "Created a chunk of size 232, which is longer than the specified 100\n",
      "Created a chunk of size 118, which is longer than the specified 100\n",
      "Created a chunk of size 142, which is longer than the specified 100\n",
      "Created a chunk of size 293, which is longer than the specified 100\n",
      "Created a chunk of size 146, which is longer than the specified 100\n",
      "Created a chunk of size 4148, which is longer than the specified 100\n",
      "Created a chunk of size 403, which is longer than the specified 100\n",
      "Created a chunk of size 146, which is longer than the specified 100\n",
      "Created a chunk of size 136, which is longer than the specified 100\n",
      "Created a chunk of size 267, which is longer than the specified 100\n",
      "Created a chunk of size 203, which is longer than the specified 100\n",
      "Created a chunk of size 541, which is longer than the specified 100\n",
      "Created a chunk of size 120, which is longer than the specified 100\n",
      "Created a chunk of size 300, which is longer than the specified 100\n",
      "Created a chunk of size 324, which is longer than the specified 100\n",
      "Created a chunk of size 281, which is longer than the specified 100\n",
      "Created a chunk of size 305, which is longer than the specified 100\n",
      "Created a chunk of size 333, which is longer than the specified 100\n",
      "Created a chunk of size 457, which is longer than the specified 100\n",
      "Created a chunk of size 421, which is longer than the specified 100\n",
      "Created a chunk of size 528, which is longer than the specified 100\n",
      "Created a chunk of size 154, which is longer than the specified 100\n",
      "Created a chunk of size 592, which is longer than the specified 100\n",
      "Created a chunk of size 633, which is longer than the specified 100\n",
      "Created a chunk of size 128, which is longer than the specified 100\n",
      "Created a chunk of size 235, which is longer than the specified 100\n",
      "Created a chunk of size 303, which is longer than the specified 100\n",
      "Created a chunk of size 658, which is longer than the specified 100\n",
      "Created a chunk of size 155, which is longer than the specified 100\n",
      "Created a chunk of size 236, which is longer than the specified 100\n",
      "Created a chunk of size 520, which is longer than the specified 100\n",
      "Created a chunk of size 172, which is longer than the specified 100\n",
      "Created a chunk of size 162, which is longer than the specified 100\n",
      "Created a chunk of size 438, which is longer than the specified 100\n",
      "Created a chunk of size 333, which is longer than the specified 100\n",
      "Created a chunk of size 581, which is longer than the specified 100\n",
      "Created a chunk of size 183, which is longer than the specified 100\n",
      "Created a chunk of size 432, which is longer than the specified 100\n",
      "Created a chunk of size 208, which is longer than the specified 100\n",
      "Created a chunk of size 242, which is longer than the specified 100\n",
      "Created a chunk of size 574, which is longer than the specified 100\n",
      "Created a chunk of size 204, which is longer than the specified 100\n",
      "Created a chunk of size 105, which is longer than the specified 100\n",
      "Created a chunk of size 741, which is longer than the specified 100\n",
      "Created a chunk of size 120, which is longer than the specified 100\n",
      "Created a chunk of size 103, which is longer than the specified 100\n",
      "Created a chunk of size 232, which is longer than the specified 100\n",
      "Created a chunk of size 118, which is longer than the specified 100\n",
      "Created a chunk of size 142, which is longer than the specified 100\n",
      "Created a chunk of size 293, which is longer than the specified 100\n"
     ]
    }
   ],
   "source": [
    "# Converts HTML to plain text \n",
    "html2text = Html2TextTransformer()\n",
    "docs_transformed = html2text.transform_documents(docs)\n",
    "\n",
    "# Chunk text\n",
    "text_splitter = CharacterTextSplitter(chunk_size=100, \n",
    "                                      chunk_overlap=0)\n",
    "chunked_documents = text_splitter.split_documents(docs_transformed)\n",
    "\n",
    "# Load chunked documents into the FAISS index\n",
    "db = FAISS.from_documents(chunked_documents, \n",
    "                          HuggingFaceEmbeddings(model_name='sentence-transformers/all-mpnet-base-v2'))\n",
    "\n",
    "retriever = db.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d54a0b-bf6c-4a24-b888-4c3283b9ccf6",
   "metadata": {},
   "source": [
    "### Create PromptTemplate and LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3bd688c2-25ac-4d65-88c6-635f9c95ada4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "### [INST] Instruction: Answer the question based on your fantasy football knowledge. Here is context to help:\n",
    "\n",
    "{context}\n",
    "\n",
    "### QUESTION:\n",
    "{question} [/INST]\n",
    " \"\"\"\n",
    "\n",
    "# Create prompt from prompt template \n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=prompt_template,\n",
    ")\n",
    "\n",
    "# Create llm chain \n",
    "llm_chain = LLMChain(llm=mistral_llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e75d34-cf63-49a8-a671-88ccb5444367",
   "metadata": {},
   "source": [
    "### Build RAG Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a1e18178-46f2-4b87-86c4-d13ff5219968",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:381: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'context': [Document(page_content='This week, Harris faces the bottom-of-the-barrel Packers’ run defense that\\nallows the ninth-most fantasy points per game to the running back position.\\nHarris will give you a higher-volume RB with a low rostership percentage this\\nweek.', metadata={'source': 'https://www.fantasypros.com/2023/11/nfl-dfs-week-10-stacking-advice-picks-2023-fantasy-football/'}),\n",
       "  Document(page_content='could start cutting into his workload. Furthermore, his rest of the season\\nschedule isn’t fantasy-friendly. Try to flip Edwards and a WR3 for Kenneth\\nWalker or Tony Pollard', metadata={'source': 'https://www.fantasypros.com/2023/11/players-to-buy-low-sell-high-trade-advice-2023-fantasy-football/'}),\n",
       "  Document(page_content='“ **Gus Edwards** has been on fire lately. He is the RB1 over the past three\\nweeks, averaging 22.2 half-point PPR fantasy points and two rushing touchdowns\\nper game. However, over 54% of his fantasy production came from the six\\nrushing touchdowns. Meanwhile, the veteran averaged only 6.5 fantasy points\\nper game over the first six contests. He had more than six fantasy points only\\nonce, in the Week 2 matchup where Edwards found the end zone. The veteran\\nrunning back is a touchdown-or-bust player, and Keaton Mitchell', metadata={'source': 'https://www.fantasypros.com/2023/11/players-to-buy-low-sell-high-trade-advice-2023-fantasy-football/'}),\n",
       "  Document(page_content=', as he should have plenty of field goal opportunities to both miss and make.\\nAt running back, I will be going with CMC and Alvin Kamara', metadata={'source': 'https://www.fantasypros.com/2023/11/rival-fantasy-nfl-week-10/'})],\n",
       " 'question': 'Should I start Gibbs next week for fantasy?',\n",
       " 'text': \"\\nBased on the information provided, it seems like there are some other options available for your fantasy team that may provide better value than starting Gibbs next week. \\n\\nFirstly, Gus Edwards has been performing well recently and could be a good option to consider. He has been the RB1 over the past three weeks and has averaged 22.2 half-point PPR fantasy points per game. Additionally, he has scored two rushing touchdowns per game. However, it's worth noting that over 54% of his fantasy production comes from the six rushing touchdowns he scored. \\n\\nAnother option to consider is Kenneth Walker or Tony Pollard. Both players have lower rostership percentages and could potentially see an increase in volume if Harris' workload decreases. \\n\\nUltimately, the decision to start Gibbs next week will depend on the specific needs and goals of your fantasy team. It may be worth considering these other options before making a final decision.\"}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain = ( \n",
    " {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | llm_chain\n",
    ")\n",
    "\n",
    "rag_chain.invoke(\"Should I start Gibbs next week for fantasy?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62895f39-9dfb-4f58-8312-72580ca03a20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-13.m111",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-13:m111"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
