{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ca0c2ec-cd58-415f-a71e-c024ac554306",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88d20621-b3b9-438e-b31e-058c9cc7ef00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-14 15:43:18.251805: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-10-14 15:43:19.466295: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForSeq2SeqLM\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import GenerationConfig\n",
    "import transformers\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    "    logging,\n",
    ")\n",
    "from peft import LoraConfig, PeftModel\n",
    "from trl import SFTTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3056255e-c817-47be-adaa-f2bc21daa282",
   "metadata": {},
   "source": [
    "### Load and test out mistral-7b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44c3be99-c274-438a-8041-b1df8129c546",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model_name='mistralai/Mistral-7B-Instruct-v0.1'\n",
    "\n",
    "model_config = transformers.AutoConfig.from_pretrained(\n",
    "    model_name,\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3380ad2c-6910-4926-b528-3230ef4a3e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# QLoRA parameters\n",
    "################################################################################\n",
    "\n",
    "# LoRA attention dimension\n",
    "lora_r = 64\n",
    "\n",
    "# Alpha parameter for LoRA scaling\n",
    "lora_alpha = 16\n",
    "\n",
    "# Dropout probability for LoRA layers\n",
    "lora_dropout = 0.1\n",
    "\n",
    "################################################################################\n",
    "# bitsandbytes parameters\n",
    "################################################################################\n",
    "\n",
    "# Activate 4-bit precision base model loading\n",
    "use_4bit = True\n",
    "\n",
    "# Compute dtype for 4-bit base models\n",
    "bnb_4bit_compute_dtype = \"float16\"\n",
    "\n",
    "# Quantization type (fp4 or nf4)\n",
    "bnb_4bit_quant_type = \"nf4\"\n",
    "\n",
    "# Activate nested quantization for 4-bit base models (double quantization)\n",
    "use_nested_quant = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b63e06c-8f91-4792-b953-a89d03fef375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Your GPU supports bfloat16: accelerate training with bf16=True\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Load tokenizer and model with QLoRA configuration\n",
    "compute_dtype = getattr(torch, bnb_4bit_compute_dtype)\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=use_4bit,\n",
    "    bnb_4bit_quant_type=bnb_4bit_quant_type,\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    "    bnb_4bit_use_double_quant=use_nested_quant,\n",
    ")\n",
    "\n",
    "# Check GPU compatibility with bfloat16\n",
    "if compute_dtype == torch.float16 and use_4bit:\n",
    "    major, _ = torch.cuda.get_device_capability()\n",
    "    if major >= 8:\n",
    "        print(\"=\" * 80)\n",
    "        print(\"Your GPU supports bfloat16: accelerate training with bf16=True\")\n",
    "        print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fee206e-cc5a-4d8a-b1d6-27007e99425f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32702566cf474d7bab679a5e84daf6e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a57c26ff-cbf1-4e91-a171-ffb7d14899bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable model parameters: 262410240\n",
      "all model parameters: 3752071168\n",
      "percentage of trainable model parameters: 6.99%\n"
     ]
    }
   ],
   "source": [
    "def print_number_of_trainable_model_parameters(model):\n",
    "    trainable_model_params = 0\n",
    "    all_model_params = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_model_params += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_model_params += param.numel()\n",
    "    return f\"trainable model parameters: {trainable_model_params}\\nall model parameters: {all_model_params}\\npercentage of trainable model parameters: {100 * trainable_model_params / all_model_params:.2f}%\"\n",
    "\n",
    "print(print_number_of_trainable_model_parameters(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "91d75a12-ccee-4eb9-afd9-fe856d7dc7b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using sep_token, but it is not set yet.\n",
      "Using cls_token, but it is not set yet.\n",
      "Using mask_token, but it is not set yet.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> [INST] What can you tell me about the 2021 fantasy football season? [/INST]The 2021 fantasy football season began on August 17th, 2021, with the first games of the NFL Preseason. The regular season started on September 11th, 2021 and ended on January 9th, 2022. The Super Bowl LVI, which was the 56th Super Bowl, was held on February 6th, 2022, at SoFi Stadium in Los Angeles, California.\n",
      "\n",
      "Due to the COVID-19 pandemic, the 2021 fantasy football season was played with some changes, including a reduced preseason schedule, the elimination of in-person attendance at games, and the use of virtual meetings for teams.\n",
      "\n",
      "In terms of fantasy football leagues, many leagues opted to use a PPR (Point Pertinent) format, which rewards players for receiving passing yards in addition to rushing yards. The use of PPR has become increasingly popular in recent years, as it provides more opportunities for players to score points.\n",
      "\n",
      "As for notable players in the 2021 fantasy football season, some of the top performers included:\n",
      "\n",
      "* Quarterbacks: Patrick Mahomes of the Kansas City Chiefs, Justin Herbert of the Los Angeles Chargers, and Tom Brady of the Tampa Bay Buccaneers.\n",
      "* Running Backs: Christian McCaffery of the Carolina Panthers, Alvin Kamara of the New Orleans Saints, and Dalvin Cook of the Minnesota Vikings.\n",
      "* Wide Receivers: Tyreek Hill of the Kansas City Chiefs, Stefon Diggs of the Buffalo Bills, and DeAndre Hopkins of the Arizona Cardinals.\n",
      "* Tight Ends: Travis Kelce of the Kansas City Chiefs, George Kittle of the San Francisco 49ers, and Tyler Higbee of the Los Angeles Rams.\n",
      "\n",
      "In terms of team performance, the Tampa Bay Buccaneers won the Super Bowl LVI, defeating the Kansas City Chiefs 31-9. The Green Bay Packers finished the regular season with the best record (13-3), but were eliminated in the divisional round of the playoffs by the Los Angeles Rams. The Oakland Raiders, who moved to Las Vegas in 2020, had a strong season, finishing with a record of 10-6 and making it to the playoffs for the first time since 2016.</s>  [INST] How many points did Maholmes score that season? [/INST]Patrick Mahomes, the quarterback for the Kansas City Chiefs, scored a total of 456 points in the regular season of the 2021 fantasy football season. This made him the top scoring quarterback in the PPR (Point Pertinent) format, which rewards players for receiving passing yards in addition to rushing yards.</s>  [INST] Can you tell me how many points he scored in week 3 of that season? [/INST]Patrick Mahomes scored 35 points in week 3 of the 2021 fantasy football season. This was a strong performance, as Mahomes completed 18 of 29 passes for 283 yards and three touchdowns in a win over the Indianapolis Colts.</s>  [INST] Did anyone score more than him in that week? [/INST]No, Patrick Mahomes did not score more than any other quarterback in week 3 of the 2021 fantasy football season. In fact, he was the top scoring quarterback in week 3, with a total of 35 points.</s>\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"What can you tell me about the 2021 fantasy football season?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"\"\"The 2021 fantasy football season began on August 17th, 2021, with the first games of the NFL Preseason. The regular season started on September 11th, 2021 and ended on January 9th, 2022. The Super Bowl LVI, which was the 56th Super Bowl, was held on February 6th, 2022, at SoFi Stadium in Los Angeles, California.\n",
    "\n",
    "Due to the COVID-19 pandemic, the 2021 fantasy football season was played with some changes, including a reduced preseason schedule, the elimination of in-person attendance at games, and the use of virtual meetings for teams.\n",
    "\n",
    "In terms of fantasy football leagues, many leagues opted to use a PPR (Point Pertinent) format, which rewards players for receiving passing yards in addition to rushing yards. The use of PPR has become increasingly popular in recent years, as it provides more opportunities for players to score points.\n",
    "\n",
    "As for notable players in the 2021 fantasy football season, some of the top performers included:\n",
    "\n",
    "* Quarterbacks: Patrick Mahomes of the Kansas City Chiefs, Justin Herbert of the Los Angeles Chargers, and Tom Brady of the Tampa Bay Buccaneers.\n",
    "* Running Backs: Christian McCaffery of the Carolina Panthers, Alvin Kamara of the New Orleans Saints, and Dalvin Cook of the Minnesota Vikings.\n",
    "* Wide Receivers: Tyreek Hill of the Kansas City Chiefs, Stefon Diggs of the Buffalo Bills, and DeAndre Hopkins of the Arizona Cardinals.\n",
    "* Tight Ends: Travis Kelce of the Kansas City Chiefs, George Kittle of the San Francisco 49ers, and Tyler Higbee of the Los Angeles Rams.\n",
    "\n",
    "In terms of team performance, the Tampa Bay Buccaneers won the Super Bowl LVI, defeating the Kansas City Chiefs 31-9. The Green Bay Packers finished the regular season with the best record (13-3), but were eliminated in the divisional round of the playoffs by the Los Angeles Rams. The Oakland Raiders, who moved to Las Vegas in 2020, had a strong season, finishing with a record of 10-6 and making it to the playoffs for the first time since 2016.\"\"\"},\n",
    "    {\"role\": \"user\", \"content\": \"How many points did Maholmes score that season?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Patrick Mahomes, the quarterback for the Kansas City Chiefs, scored a total of 456 points in the regular season of the 2021 fantasy football season. This made him the top scoring quarterback in the PPR (Point Pertinent) format, which rewards players for receiving passing yards in addition to rushing yards.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Can you tell me how many points he scored in week 3 of that season?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Patrick Mahomes scored 35 points in week 3 of the 2021 fantasy football season. This was a strong performance, as Mahomes completed 18 of 29 passes for 283 yards and three touchdowns in a win over the Indianapolis Colts.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Did anyone score more than him in that week?\"}\n",
    "]\n",
    "\n",
    "encodeds = tokenizer.apply_chat_template(messages, return_tensors=\"pt\")\n",
    "\n",
    "model_inputs = encodeds.to(device)\n",
    "model\n",
    "\n",
    "generated_ids = model.generate(model_inputs, max_new_tokens=1000, do_sample=True)\n",
    "decoded = tokenizer.batch_decode(generated_ids)\n",
    "print(decoded[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04528bc9-a21c-44e0-a89e-6adf7e27cfae",
   "metadata": {},
   "source": [
    "### RAG RAG RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b6321da6-e3e3-4680-a4a8-15e90c0cc8f6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Obtaining dependency information for langchain from https://files.pythonhosted.org/packages/5a/52/851a5e896ead3c22b04caab67b38805f9dbfa7b59e69b5d9dcd06a6a6c9b/langchain-0.0.314-py3-none-any.whl.metadata\n",
      "  Downloading langchain-0.0.314-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting openai\n",
      "  Obtaining dependency information for openai from https://files.pythonhosted.org/packages/1e/9f/385c25502f437686e4aa715969e5eaf5c2cb5e5ffa7c5cdd52f3c6ae967a/openai-0.28.1-py3-none-any.whl.metadata\n",
      "  Downloading openai-0.28.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting faiss-gpu\n",
      "  Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tiktoken\n",
      "  Obtaining dependency information for tiktoken from https://files.pythonhosted.org/packages/f4/2e/0adf6e264b996e263b1c57cad6560ffd5492a69beb9fd779ed0463d486bc/tiktoken-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading tiktoken-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.0.20)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (3.8.5)\n",
      "Requirement already satisfied: anyio<4.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (3.7.1)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (4.0.3)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
      "  Obtaining dependency information for dataclasses-json<0.7,>=0.5.7 from https://files.pythonhosted.org/packages/21/1f/1cff009cff64420572b9f75b70e4a054095719179a172297dfdd65843162/dataclasses_json-0.6.1-py3-none-any.whl.metadata\n",
      "  Downloading dataclasses_json-0.6.1-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
      "  Obtaining dependency information for jsonpatch<2.0,>=1.33 from https://files.pythonhosted.org/packages/73/07/02e16ed01e04a374e644b575638ec7987ae846d25ad97bcc9945a3ee4b0e/jsonpatch-1.33-py2.py3-none-any.whl.metadata\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langsmith<0.1.0,>=0.0.43 (from langchain)\n",
      "  Obtaining dependency information for langsmith<0.1.0,>=0.0.43 from https://files.pythonhosted.org/packages/9b/6c/fd466f647634ef4a668ea109bf0892d7f78882ffe09500429081ed6dae4a/langsmith-0.0.43-py3-none-any.whl.metadata\n",
      "  Downloading langsmith-0.0.43-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.23.5)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.10.12)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from openai) (4.66.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.10/site-packages (from tiktoken) (2023.8.8)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<4.0->langchain) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio<4.0->langchain) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from anyio<4.0->langchain) (1.1.3)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Obtaining dependency information for marshmallow<4.0.0,>=3.18.0 from https://files.pythonhosted.org/packages/ed/3c/cebfdcad015240014ff08b883d1c0c427f2ba45ae8c6572851b6ef136cad/marshmallow-3.20.1-py3-none-any.whl.metadata\n",
      "  Downloading marshmallow-3.20.1-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Obtaining dependency information for typing-inspect<1,>=0.4.0 from https://files.pythonhosted.org/packages/65/f3/107a22063bf27bdccf2024833d3445f4eea42b2e598abfbd46f6a63b6cb0/typing_inspect-0.9.0-py3-none-any.whl.metadata\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (4.5.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
      "Requirement already satisfied: packaging>=17.0 in /opt/conda/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain) (23.1)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Downloading langchain-0.0.314-py3-none-any.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m87.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading openai-0.28.1-py3-none-any.whl (76 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tiktoken-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m54.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading dataclasses_json-0.6.1-py3-none-any.whl (27 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langsmith-0.0.43-py3-none-any.whl (40 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.0/40.0 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Installing collected packages: faiss-gpu, mypy-extensions, marshmallow, jsonpatch, typing-inspect, tiktoken, langsmith, openai, dataclasses-json, langchain\n",
      "  Attempting uninstall: jsonpatch\n",
      "    Found existing installation: jsonpatch 1.32\n",
      "    Uninstalling jsonpatch-1.32:\n",
      "      Successfully uninstalled jsonpatch-1.32\n",
      "Successfully installed dataclasses-json-0.6.1 faiss-gpu-1.7.2 jsonpatch-1.33 langchain-0.0.314 langsmith-0.0.43 marshmallow-3.20.1 mypy-extensions-1.0.0 openai-0.28.1 tiktoken-0.5.1 typing-inspect-0.9.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain openai faiss-gpu tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d5781288-c466-45b9-a5bd-33b09012afbd",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.34.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.66.1)\n",
      "Requirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (2.0.1)\n",
      "Collecting torchvision (from sentence-transformers)\n",
      "  Obtaining dependency information for torchvision from https://files.pythonhosted.org/packages/84/eb/4f6483ae9094e164dc5b9b792e377f7d37823b0bedc3eef3193d416d2bb6/torchvision-0.16.0-cp310-cp310-manylinux1_x86_64.whl.metadata\n",
      "  Downloading torchvision-0.16.0-cp310-cp310-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.23.5)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.11.2)\n",
      "Collecting nltk (from sentence-transformers)\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting sentencepiece (from sentence-transformers)\n",
      "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m78.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.17.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.12.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2023.6.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.31.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.5.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.1)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (2.0.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.6.0->sentence-transformers) (68.1.2)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.6.0->sentence-transformers) (0.41.2)\n",
      "Requirement already satisfied: cmake in /opt/conda/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers) (3.27.5)\n",
      "Requirement already satisfied: lit in /opt/conda/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers) (17.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2023.8.8)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.14.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.3.3)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk->sentence-transformers) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk->sentence-transformers) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.2.0)\n",
      "Collecting torch>=1.6.0 (from sentence-transformers)\n",
      "  Obtaining dependency information for torch>=1.6.0 from https://files.pythonhosted.org/packages/6d/13/b5e8bacd980b2195f8a1741ce11cbb9146568607795d5e4ff510dcff1064/torch-2.1.0-cp310-cp310-manylinux1_x86_64.whl.metadata\n",
      "  Downloading torch-2.1.0-cp310-cp310-manylinux1_x86_64.whl.metadata (25 kB)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->sentence-transformers) (10.0.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.6.0->sentence-transformers)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.6.0->sentence-transformers)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m65.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.6.0->sentence-transformers)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m85.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.6.0->sentence-transformers)\n",
      "  Obtaining dependency information for nvidia-cudnn-cu12==8.9.2.26 from https://files.pythonhosted.org/packages/ff/74/a2e2be7fb83aaedec84f391f082cf765dfb635e7caa9b49065f73e4835d8/nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata\n",
      "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.6.0->sentence-transformers)\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.6.0->sentence-transformers)\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.6.0->sentence-transformers)\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.6.0->sentence-transformers)\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.6.0->sentence-transformers)\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nccl-cu12==2.18.1 (from torch>=1.6.0->sentence-transformers)\n",
      "  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.6.0->sentence-transformers)\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting triton==2.1.0 (from torch>=1.6.0->sentence-transformers)\n",
      "  Obtaining dependency information for triton==2.1.0 from https://files.pythonhosted.org/packages/4d/22/91a8af421c8a8902dde76e6ef3db01b258af16c53d81e8c0d0dc13900a9e/triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata\n",
      "  Downloading triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.6.0->sentence-transformers)\n",
      "  Obtaining dependency information for nvidia-nvjitlink-cu12 from https://files.pythonhosted.org/packages/0a/f8/5193b57555cbeecfdb6ade643df0d4218cc6385485492b6e2f64ceae53bb/nvidia_nvjitlink_cu12-12.2.140-py3-none-manylinux1_x86_64.whl.metadata\n",
      "  Downloading nvidia_nvjitlink_cu12-12.2.140-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.3.0)\n",
      "Downloading torchvision-0.16.0-cp310-cp310-manylinux1_x86_64.whl (6.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m93.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.1.0-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m840.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m903.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.2/89.2 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m0:01\u001b[0mm\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.2.140-py3-none-manylinux1_x86_64.whl (20.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.2/20.2 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: sentence-transformers\n",
      "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125923 sha256=d73943222fdb3cc9fb10db786ddf439749d33e68f3f88e9aa02a743c42f13337\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n",
      "Successfully built sentence-transformers\n",
      "Installing collected packages: sentencepiece, triton, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nltk, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision, sentence-transformers\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 2.0.0\n",
      "    Uninstalling triton-2.0.0:\n",
      "      Successfully uninstalled triton-2.0.0\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.0.1\n",
      "    Uninstalling torch-2.0.1:\n",
      "      Successfully uninstalled torch-2.0.1\n",
      "Successfully installed nltk-3.8.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvjitlink-cu12-12.2.140 nvidia-nvtx-cu12-12.1.105 sentence-transformers-2.2.2 sentencepiece-0.1.99 torch-2.1.0 torchvision-0.16.0 triton-2.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b11d3eec-143a-4c73-8b41-5b33550204cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!playwright install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adc9b45f-91f0-4340-b411-61a2ba6fc498",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74c55b2-9f12-44ef-891e-c4cbca5dec13",
   "metadata": {},
   "source": [
    "Example ChatPromptTemplate\n",
    "\n",
    "```python\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful AI bot. Your name is {name}.\"),\n",
    "    (\"human\", \"Hello, how are you doing?\"),\n",
    "    (\"ai\", \"I'm doing well, thanks!\"),\n",
    "    (\"human\", \"{user_input}\"),\n",
    "])\n",
    "\n",
    "messages = template.format_messages(\n",
    "    name=\"Bob\",\n",
    "    user_input=\"What is your name?\"\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbcc6409-d423-4699-804a-72341332efb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_generation_pipeline = transformers.pipeline(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    task=\"text-generation\",\n",
    "    temperature=0.2,\n",
    "    repetition_penalty=1.1,\n",
    "    return_full_text=True,\n",
    "    max_new_tokens=1000,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4865d5fa-dae3-41fb-81d2-5659e631cd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "mistral_llm = HuggingFacePipeline(pipeline=text_generation_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5654ae72-31a9-4c54-84cc-9cc3e5e4864e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "### [INST] Instruction: Answer the question based on your fantasy football knowledge. Here is context to help:\n",
    "\n",
    "{context}\n",
    "\n",
    "### QUESTION:\n",
    "{question} [/INST]\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95c95f07-2802-4cda-ba5e-06b16a9592c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create prompt from prompt template \n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=prompt_template,\n",
    ")\n",
    "\n",
    "# Create llm chain \n",
    "llm_chain = LLMChain(llm=mistral_llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "956cd4fb-3111-48b6-88da-13b51cdbec9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:362: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Patrick Mahomes is a professional American football player who plays quarterback for the Kansas City Chiefs in the National Football League (NFL). In the 2023 season, he would have scored fantasy football points based on his performance in games throughout the year. However, as the 2023 season has not yet started and the final scores are unknown, I cannot provide an answer to this question at this time.\n"
     ]
    }
   ],
   "source": [
    "input_text = {\n",
    "    \"context\": \"\",\n",
    "    \"question\": \"How many fantasy football points did patrick maholmes score in the 2023 season?\"\n",
    "}\n",
    "\n",
    "# Generate and print LLM response \n",
    "response = llm_chain(input_text)\n",
    "\n",
    "print(response['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "5b94ecc6-489c-4b66-82ab-3896ad143397",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = FAISS.from_texts([\"In the 2023 session, patrick maholmes scored 2000 fantasy football points.\"], embedding=HuggingFaceEmbeddings())\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e49383a-4cd9-41cd-b5e2-f5053ed15eb8",
   "metadata": {},
   "source": [
    "```python\n",
    "HuggingFaceEmbeddings(\n",
    "    *,\n",
    "    client: Any = None,\n",
    "    model_name: str = 'sentence-transformers/all-mpnet-base-v2',\n",
    "    cache_folder: Optional[str] = None,\n",
    "    model_kwargs: Dict[str, Any] = None,\n",
    "    encode_kwargs: Dict[str, Any] = None,\n",
    "    multi_process: bool = False,\n",
    ") -> None\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "9d7e5e98-0ef3-4818-b9bb-3cfdedba351f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = ( \n",
    " {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | llm_chain\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "2798a94e-6a6a-4c60-9c2f-4f3d7ac69530",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:362: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'context': [Document(page_content='In the 2023 session, patrick maholmes scored 2000 fantasy football points.')],\n",
       " 'question': 'How many fantasy football points did patrick maholmes score in the 2023 season?',\n",
       " 'text': ' Patrick Mahomes scored 2000 fantasy football points in the 2023 season.'}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"How many fantasy football points did patrick maholmes score in the 2023 season?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "a2cec562-9798-486e-b9ba-86949faa2a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting unstructured\n",
      "  Obtaining dependency information for unstructured from https://files.pythonhosted.org/packages/86/26/440da052da58a71b895009eaff33564472633efb4f481011e01b75ec8037/unstructured-0.10.22-py3-none-any.whl.metadata\n",
      "  Downloading unstructured-0.10.22-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting chardet (from unstructured)\n",
      "  Obtaining dependency information for chardet from https://files.pythonhosted.org/packages/38/6f/f5fbc992a329ee4e0f288c1fe0e2ad9485ed064cac731ed2fe47dcc38cbf/chardet-5.2.0-py3-none-any.whl.metadata\n",
      "  Downloading chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting filetype (from unstructured)\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Collecting python-magic (from unstructured)\n",
      "  Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
      "Collecting lxml (from unstructured)\n",
      "  Obtaining dependency information for lxml from https://files.pythonhosted.org/packages/3c/d2/11533f0bc47ff4d828a20cfb702f3453fe714bd5b475fcdc8cec6e6b7dcf/lxml-4.9.3-cp310-cp310-manylinux_2_28_x86_64.whl.metadata\n",
      "  Downloading lxml-4.9.3-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from unstructured) (3.8.1)\n",
      "Requirement already satisfied: tabulate in /opt/conda/lib/python3.10/site-packages (from unstructured) (0.9.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from unstructured) (2.31.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from unstructured) (4.12.2)\n",
      "Collecting emoji (from unstructured)\n",
      "  Obtaining dependency information for emoji from https://files.pythonhosted.org/packages/96/c6/0114b2040a96561fd1b44c75df749bbd3c898bf8047fb5ce8d7590d2dee6/emoji-2.8.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading emoji-2.8.0-py2.py3-none-any.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: dataclasses-json in /opt/conda/lib/python3.10/site-packages (from unstructured) (0.6.1)\n",
      "Collecting python-iso639 (from unstructured)\n",
      "  Obtaining dependency information for python-iso639 from https://files.pythonhosted.org/packages/b8/6d/5d1f7e5c1b0c58b700eb67dbb570f9381afc90bc0535686a89e90eac5dfb/python_iso639-2023.6.15-py3-none-any.whl.metadata\n",
      "  Downloading python_iso639-2023.6.15-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting langdetect (from unstructured)\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from unstructured) (1.23.5)\n",
      "Collecting rapidfuzz (from unstructured)\n",
      "  Obtaining dependency information for rapidfuzz from https://files.pythonhosted.org/packages/f3/d2/1a45332198da8ddb904ef584a79a5258dda6e59f9be0ee16540cbb0a16c1/rapidfuzz-3.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading rapidfuzz-3.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: backoff in /opt/conda/lib/python3.10/site-packages (from unstructured) (2.2.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->unstructured) (2.3.2.post1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json->unstructured) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json->unstructured) (0.9.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from langdetect->unstructured) (1.16.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk->unstructured) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk->unstructured) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk->unstructured) (2023.8.8)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from nltk->unstructured) (4.66.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->unstructured) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->unstructured) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->unstructured) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->unstructured) (2023.7.22)\n",
      "Requirement already satisfied: packaging>=17.0 in /opt/conda/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->unstructured) (23.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->unstructured) (1.0.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->unstructured) (4.5.0)\n",
      "Downloading unstructured-0.10.22-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading chardet-5.2.0-py3-none-any.whl (199 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.4/199.4 kB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading emoji-2.8.0-py2.py3-none-any.whl (358 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m358.9/358.9 kB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading lxml-4.9.3-cp310-cp310-manylinux_2_28_x86_64.whl (7.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m77.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading python_iso639-2023.6.15-py3-none-any.whl (275 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m275.1/275.1 kB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rapidfuzz-3.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m105.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: langdetect\n",
      "  Building wheel for langdetect (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993224 sha256=49a58c3a2f67778769dc302fe1f2e8264a1e2e5424fc7ab2d87ec85af4709676\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
      "Successfully built langdetect\n",
      "Installing collected packages: filetype, rapidfuzz, python-magic, python-iso639, lxml, langdetect, emoji, chardet, unstructured\n",
      "Successfully installed chardet-5.2.0 emoji-2.8.0 filetype-1.2.0 langdetect-1.0.9 lxml-4.9.3 python-iso639-2023.6.15 python-magic-0.4.27 rapidfuzz-3.4.0 unstructured-0.10.22\n"
     ]
    }
   ],
   "source": [
    "!pip install unstructured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "995e4561-2139-4424-b959-635be93e1026",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import AsyncChromiumLoader, UnstructuredURLLoader, PlaywrightURLLoader\n",
    "from langchain.document_loaders.blob_loaders.schema import Blob\n",
    "from langchain.document_loaders.parsers.txt import TextParser\n",
    "from langchain.document_loaders.url_selenium import SeleniumURLLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00665637-892a-4f91-ab45-302a119a07e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_document = \"\"\"\n",
    "ALLEN PARK, Mich. -- Detroit Lions running back Jahmyr Gibbs has been ruled out for Sunday's game against the Tampa Bay Buccaneers with a hamstring injury while Pro Bowl receiver Amon-Ra St. Brown (abdomen) is set to make his return.\n",
    "\n",
    "Gibbs, who did not practice this week, also missed last week's 42-24 victory over the Carolina Panthers with the same injury. With 179 yards and a touchdown with an additional 70 receiving yards in his four appearances, he is Detroit's second-leading rusher.\n",
    "\n",
    "Veteran running back David Montgomery has carried the load in his absence, with back-to-back games of at least 100 yards rushing. Detroit has rushed for nine touchdowns through the first five games of the season, tying a team record.\n",
    "\n",
    "Although expectations are high for Gibbs as the Lions' No. 12 overall selection, running back coach Scottie Montgomery is helping him develop at his own pace.\n",
    "\n",
    "\"He's right where I thought he would be, he's right where he should be coming along at at this time,\" Scottie Montgomery said.\n",
    "\n",
    "\"We don't judge players based off of anything else besides achievement. Like there is success and there is expectations and I want people outside the building to put those expectations on him because, guess what, whether we believe it or not it motivates him. It does and that's a really, really good tool.\"\n",
    "\n",
    "Meanwhile, rookie safety Brian Branch, who has an ankle injury, is also set to miss his second consecutive game. The second-round pick out of Alabama was held out of practice for the entire week. With 25 tackles, a pick-six and 4 passes defended, he is Detroit's fourth-leading tackler.\n",
    "\n",
    "Rookie tight end Sam LaPorta is questionable with a calf strain that flared up Wednesday, forcing him to miss Thursday's practice. He said it likely stemmed from Sunday's win over Carolina, and he intends to play Sunday.\n",
    "\n",
    "\"It's football, things happen, we certainly work our bodies pretty hard so I'm feeling a lot better today,\" LaPorta said.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15bbffac-c547-4507-b066-e918e6553e74",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "asyncio.run() cannot be called from a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m loader \u001b[38;5;241m=\u001b[39m AsyncChromiumLoader([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.espn.com/nfl/story/_/id/38652877/lions-rb-jahmyr-gibbs-wr-amon-ra-st-brown-return-vs-bucs\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m----> 2\u001b[0m \u001b[43mloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain/document_loaders/chromium.py:90\u001b[0m, in \u001b[0;36mAsyncChromiumLoader.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Document]:\n\u001b[1;32m     82\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;124;03m    Load and return all Documents from the provided URLs.\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     88\u001b[0m \n\u001b[1;32m     89\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 90\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlazy_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain/document_loaders/chromium.py:77\u001b[0m, in \u001b[0;36mAsyncChromiumLoader.lazy_load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;124;03mLazily load text content from the provided URLs.\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     74\u001b[0m \n\u001b[1;32m     75\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m url \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murls:\n\u001b[0;32m---> 77\u001b[0m     html_content \u001b[38;5;241m=\u001b[39m \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mascrape_playwright\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: url}\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m Document(page_content\u001b[38;5;241m=\u001b[39mhtml_content, metadata\u001b[38;5;241m=\u001b[39mmetadata)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/asyncio/runners.py:33\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(main, debug)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the coroutine and return the result.\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;03mThis function runs the passed coroutine, taking care of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;124;03m    asyncio.run(main())\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m events\u001b[38;5;241m.\u001b[39m_get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 33\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     34\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masyncio.run() cannot be called from a running event loop\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m coroutines\u001b[38;5;241m.\u001b[39miscoroutine(main):\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma coroutine was expected, got \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(main))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: asyncio.run() cannot be called from a running event loop"
     ]
    }
   ],
   "source": [
    "loader = AsyncChromiumLoader([\"https://www.espn.com/nfl/story/_/id/38652877/lions-rb-jahmyr-gibbs-wr-amon-ra-st-brown-return-vs-bucs\"])\n",
    "loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "f9e10dc6-d940-45ea-87f0-b8ac37d10a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Chromium 117.0.5938.62 (playwright build v1080)\u001b[2m from https://playwright.azureedge.net/builds/chromium/1080/chromium-linux.zip\u001b[22m\n",
      "\u001b[1G153.1 Mb [                    ] 0% 10.1s\u001b[0K\u001b[1G153.1 Mb [                    ] 0% 31.2s\u001b[0K\u001b[1G153.1 Mb [                    ] 0% 20.2s\u001b[0K\u001b[1G153.1 Mb [                    ] 0% 9.4s\u001b[0K\u001b[1G153.1 Mb [                    ] 1% 5.5s\u001b[0K\u001b[1G153.1 Mb [                    ] 2% 3.7s\u001b[0K\u001b[1G153.1 Mb [=                   ] 3% 2.8s\u001b[0K\u001b[1G153.1 Mb [=                   ] 4% 2.7s\u001b[0K\u001b[1G153.1 Mb [=                   ] 5% 2.3s\u001b[0K\u001b[1G153.1 Mb [=                   ] 7% 1.8s\u001b[0K\u001b[1G153.1 Mb [==                  ] 8% 1.7s\u001b[0K\u001b[1G153.1 Mb [==                  ] 9% 1.7s\u001b[0K\u001b[1G153.1 Mb [==                  ] 11% 1.5s\u001b[0K\u001b[1G153.1 Mb [===                 ] 12% 1.4s\u001b[0K\u001b[1G153.1 Mb [===                 ] 13% 1.4s\u001b[0K\u001b[1G153.1 Mb [===                 ] 15% 1.4s\u001b[0K\u001b[1G153.1 Mb [===                 ] 16% 1.3s\u001b[0K\u001b[1G153.1 Mb [====                ] 17% 1.3s\u001b[0K\u001b[1G153.1 Mb [====                ] 18% 1.3s\u001b[0K\u001b[1G153.1 Mb [====                ] 19% 1.2s\u001b[0K\u001b[1G153.1 Mb [====                ] 21% 1.2s\u001b[0K\u001b[1G153.1 Mb [=====               ] 23% 1.1s\u001b[0K\u001b[1G153.1 Mb [=====               ] 24% 1.1s\u001b[0K\u001b[1G153.1 Mb [=====               ] 25% 1.1s\u001b[0K\u001b[1G153.1 Mb [=====               ] 27% 1.0s\u001b[0K\u001b[1G153.1 Mb [======              ] 29% 1.0s\u001b[0K\u001b[1G153.1 Mb [======              ] 30% 1.0s\u001b[0K\u001b[1G153.1 Mb [======              ] 31% 0.9s\u001b[0K\u001b[1G153.1 Mb [=======             ] 33% 0.9s\u001b[0K\u001b[1G153.1 Mb [=======             ] 35% 0.9s\u001b[0K\u001b[1G153.1 Mb [=======             ] 37% 0.8s\u001b[0K\u001b[1G153.1 Mb [========            ] 38% 0.8s\u001b[0K\u001b[1G153.1 Mb [========            ] 40% 0.8s\u001b[0K\u001b[1G153.1 Mb [========            ] 42% 0.7s\u001b[0K\u001b[1G153.1 Mb [=========           ] 43% 0.7s\u001b[0K\u001b[1G153.1 Mb [=========           ] 45% 0.7s\u001b[0K\u001b[1G153.1 Mb [=========           ] 47% 0.6s\u001b[0K\u001b[1G153.1 Mb [==========          ] 49% 0.6s\u001b[0K\u001b[1G153.1 Mb [==========          ] 50% 0.6s\u001b[0K\u001b[1G153.1 Mb [===========         ] 52% 0.6s\u001b[0K\u001b[1G153.1 Mb [===========         ] 54% 0.5s\u001b[0K\u001b[1G153.1 Mb [===========         ] 56% 0.5s\u001b[0K\u001b[1G153.1 Mb [============        ] 58% 0.5s\u001b[0K\u001b[1G153.1 Mb [============        ] 59% 0.5s\u001b[0K\u001b[1G153.1 Mb [============        ] 62% 0.4s\u001b[0K\u001b[1G153.1 Mb [=============       ] 64% 0.4s\u001b[0K\u001b[1G153.1 Mb [=============       ] 66% 0.4s\u001b[0K\u001b[1G153.1 Mb [==============      ] 68% 0.4s\u001b[0K\u001b[1G153.1 Mb [==============      ] 69% 0.3s\u001b[0K\u001b[1G153.1 Mb [==============      ] 71% 0.3s\u001b[0K\u001b[1G153.1 Mb [===============     ] 74% 0.3s\u001b[0K\u001b[1G153.1 Mb [===============     ] 76% 0.3s\u001b[0K\u001b[1G153.1 Mb [================    ] 78% 0.2s\u001b[0K\u001b[1G153.1 Mb [================    ] 80% 0.2s\u001b[0K\u001b[1G153.1 Mb [================    ] 82% 0.2s\u001b[0K\u001b[1G153.1 Mb [=================   ] 84% 0.2s\u001b[0K\u001b[1G153.1 Mb [=================   ] 86% 0.1s\u001b[0K\u001b[1G153.1 Mb [==================  ] 89% 0.1s\u001b[0K\u001b[1G153.1 Mb [==================  ] 91% 0.1s\u001b[0K\u001b[1G153.1 Mb [=================== ] 93% 0.1s\u001b[0K\u001b[1G153.1 Mb [=================== ] 95% 0.0s\u001b[0K\u001b[1G153.1 Mb [====================] 97% 0.0s\u001b[0K\u001b[1G153.1 Mb [====================] 99% 0.0s\u001b[0K\u001b[1G153.1 Mb [====================] 100% 0.0s\u001b[0K\n",
      "Chromium 117.0.5938.62 (playwright build v1080) downloaded to /home/jupyter/.cache/ms-playwright/chromium-1080\n",
      "Downloading FFMPEG playwright build v1009\u001b[2m from https://playwright.azureedge.net/builds/ffmpeg/1009/ffmpeg-linux.zip\u001b[22m\n",
      "\u001b[1G2.6 Mb [                    ] 0% 0.0s\u001b[0K\u001b[1G2.6 Mb [                    ] 2% 0.9s\u001b[0K\u001b[1G2.6 Mb [=                   ] 7% 0.6s\u001b[0K\u001b[1G2.6 Mb [===                 ] 17% 0.3s\u001b[0K\u001b[1G2.6 Mb [=======             ] 33% 0.2s\u001b[0K\u001b[1G2.6 Mb [============        ] 59% 0.1s\u001b[0K\u001b[1G2.6 Mb [=================   ] 85% 0.0s\u001b[0K\u001b[1G2.6 Mb [====================] 100% 0.0s\u001b[0K\n",
      "FFMPEG playwright build v1009 downloaded to /home/jupyter/.cache/ms-playwright/ffmpeg-1009\n",
      "Downloading Firefox 117.0 (playwright build v1424)\u001b[2m from https://playwright.azureedge.net/builds/firefox/1424/firefox-debian-11.zip\u001b[22m\n",
      "\u001b[1G78.8 Mb [                    ] 0% 0.0s\u001b[0K\u001b[1G78.8 Mb [                    ] 0% 14.3s\u001b[0K\u001b[1G78.8 Mb [                    ] 0% 8.7s\u001b[0K\u001b[1G78.8 Mb [                    ] 1% 4.6s\u001b[0K\u001b[1G78.8 Mb [=                   ] 2% 2.5s\u001b[0K\u001b[1G78.8 Mb [=                   ] 4% 1.8s\u001b[0K\u001b[1G78.8 Mb [=                   ] 6% 1.4s\u001b[0K\u001b[1G78.8 Mb [==                  ] 8% 1.3s\u001b[0K\u001b[1G78.8 Mb [==                  ] 10% 1.1s\u001b[0K\u001b[1G78.8 Mb [==                  ] 11% 1.1s\u001b[0K\u001b[1G78.8 Mb [===                 ] 14% 1.0s\u001b[0K\u001b[1G78.8 Mb [===                 ] 17% 0.9s\u001b[0K\u001b[1G78.8 Mb [====                ] 20% 0.8s\u001b[0K\u001b[1G78.8 Mb [====                ] 22% 0.7s\u001b[0K\u001b[1G78.8 Mb [=====               ] 24% 0.7s\u001b[0K\u001b[1G78.8 Mb [=====               ] 27% 0.7s\u001b[0K\u001b[1G78.8 Mb [======              ] 28% 0.7s\u001b[0K\u001b[1G78.8 Mb [======              ] 30% 0.6s\u001b[0K\u001b[1G78.8 Mb [=======             ] 33% 0.6s\u001b[0K\u001b[1G78.8 Mb [=======             ] 36% 0.5s\u001b[0K\u001b[1G78.8 Mb [========            ] 40% 0.5s\u001b[0K\u001b[1G78.8 Mb [=========           ] 43% 0.4s\u001b[0K\u001b[1G78.8 Mb [=========           ] 45% 0.4s\u001b[0K\u001b[1G78.8 Mb [==========          ] 48% 0.4s\u001b[0K\u001b[1G78.8 Mb [===========         ] 52% 0.3s\u001b[0K\u001b[1G78.8 Mb [===========         ] 55% 0.3s\u001b[0K\u001b[1G78.8 Mb [============        ] 59% 0.3s\u001b[0K\u001b[1G78.8 Mb [============        ] 62% 0.3s\u001b[0K\u001b[1G78.8 Mb [=============       ] 64% 0.2s\u001b[0K\u001b[1G78.8 Mb [==============      ] 67% 0.2s\u001b[0K\u001b[1G78.8 Mb [==============      ] 71% 0.2s\u001b[0K\u001b[1G78.8 Mb [===============     ] 75% 0.2s\u001b[0K\u001b[1G78.8 Mb [================    ] 79% 0.1s\u001b[0K\u001b[1G78.8 Mb [=================   ] 82% 0.1s\u001b[0K\u001b[1G78.8 Mb [=================   ] 85% 0.1s\u001b[0K\u001b[1G78.8 Mb [=================   ] 86% 0.1s\u001b[0K\u001b[1G78.8 Mb [==================  ] 90% 0.1s\u001b[0K\u001b[1G78.8 Mb [=================== ] 94% 0.0s\u001b[0K\u001b[1G78.8 Mb [=================== ] 96% 0.0s\u001b[0K\u001b[1G78.8 Mb [====================] 100% 0.0s\u001b[0K\n",
      "Firefox 117.0 (playwright build v1424) downloaded to /home/jupyter/.cache/ms-playwright/firefox-1424\n",
      "Downloading Webkit 17.0 (playwright build v1908)\u001b[2m from https://playwright.azureedge.net/builds/webkit/1908/webkit-debian-11.zip\u001b[22m\n",
      "\u001b[1G87.7 Mb [                    ] 0% 0.0s\u001b[0K\u001b[1G87.7 Mb [                    ] 0% 28.3s\u001b[0K\u001b[1G87.7 Mb [                    ] 0% 19.7s\u001b[0K\u001b[1G87.7 Mb [                    ] 0% 12.6s\u001b[0K\u001b[1G87.7 Mb [                    ] 1% 8.2s\u001b[0K\u001b[1G87.7 Mb [                    ] 1% 5.7s\u001b[0K\u001b[1G87.7 Mb [=                   ] 2% 4.4s\u001b[0K\u001b[1G87.7 Mb [=                   ] 3% 3.8s\u001b[0K\u001b[1G87.7 Mb [=                   ] 4% 3.1s\u001b[0K\u001b[1G87.7 Mb [=                   ] 6% 2.7s\u001b[0K\u001b[1G87.7 Mb [=                   ] 7% 2.4s\u001b[0K\u001b[1G87.7 Mb [==                  ] 9% 2.0s\u001b[0K\u001b[1G87.7 Mb [==                  ] 12% 1.6s\u001b[0K\u001b[1G87.7 Mb [===                 ] 14% 1.4s\u001b[0K\u001b[1G87.7 Mb [===                 ] 16% 1.3s\u001b[0K\u001b[1G87.7 Mb [====                ] 18% 1.2s\u001b[0K\u001b[1G87.7 Mb [====                ] 21% 1.1s\u001b[0K\u001b[1G87.7 Mb [=====               ] 23% 1.0s\u001b[0K\u001b[1G87.7 Mb [=====               ] 26% 0.9s\u001b[0K\u001b[1G87.7 Mb [======              ] 29% 0.8s\u001b[0K\u001b[1G87.7 Mb [======              ] 31% 0.8s\u001b[0K\u001b[1G87.7 Mb [=======             ] 34% 0.7s\u001b[0K\u001b[1G87.7 Mb [=======             ] 35% 0.7s\u001b[0K\u001b[1G87.7 Mb [========            ] 38% 0.6s\u001b[0K\u001b[1G87.7 Mb [========            ] 40% 0.6s\u001b[0K\u001b[1G87.7 Mb [=========           ] 43% 0.6s\u001b[0K\u001b[1G87.7 Mb [=========           ] 46% 0.5s\u001b[0K\u001b[1G87.7 Mb [==========          ] 48% 0.5s\u001b[0K\u001b[1G87.7 Mb [==========          ] 51% 0.5s\u001b[0K\u001b[1G87.7 Mb [===========         ] 54% 0.4s\u001b[0K\u001b[1G87.7 Mb [===========         ] 56% 0.4s\u001b[0K\u001b[1G87.7 Mb [============        ] 58% 0.4s\u001b[0K\u001b[1G87.7 Mb [============        ] 61% 0.3s\u001b[0K\u001b[1G87.7 Mb [=============       ] 65% 0.3s\u001b[0K\u001b[1G87.7 Mb [=============       ] 67% 0.3s\u001b[0K\u001b[1G87.7 Mb [==============      ] 70% 0.2s\u001b[0K\u001b[1G87.7 Mb [===============     ] 72% 0.2s\u001b[0K\u001b[1G87.7 Mb [===============     ] 76% 0.2s\u001b[0K\u001b[1G87.7 Mb [================    ] 78% 0.2s\u001b[0K\u001b[1G87.7 Mb [================    ] 81% 0.1s\u001b[0K\u001b[1G87.7 Mb [=================   ] 83% 0.1s\u001b[0K\u001b[1G87.7 Mb [=================   ] 85% 0.1s\u001b[0K\u001b[1G87.7 Mb [==================  ] 89% 0.1s\u001b[0K\u001b[1G87.7 Mb [==================  ] 92% 0.1s\u001b[0K\u001b[1G87.7 Mb [=================== ] 94% 0.0s\u001b[0K\u001b[1G87.7 Mb [=================== ] 97% 0.0s\u001b[0K\u001b[1G87.7 Mb [====================] 100% 0.0s\u001b[0K\n",
      "Webkit 17.0 (playwright build v1908) downloaded to /home/jupyter/.cache/ms-playwright/webkit-1908\n"
     ]
    }
   ],
   "source": [
    "!playwright install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "35fd1385-aa12-4a22-8bd7-94045b073c97",
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "It looks like you are using Playwright Sync API inside the asyncio loop.\nPlease use the Async API instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mError\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[186], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m loader \u001b[38;5;241m=\u001b[39m PlaywrightURLLoader([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.espn.com/nfl/story/_/id/38652877/lions-rb-jahmyr-gibbs-wr-amon-ra-st-brown-return-vs-bucs\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m----> 2\u001b[0m \u001b[43mloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain/document_loaders/url_playwright.py:154\u001b[0m, in \u001b[0;36mPlaywrightURLLoader.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mplaywright\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msync_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sync_playwright\n\u001b[1;32m    152\u001b[0m docs: List[Document] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m()\n\u001b[0;32m--> 154\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sync_playwright() \u001b[38;5;28;01mas\u001b[39;00m p:\n\u001b[1;32m    155\u001b[0m     browser \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mchromium\u001b[38;5;241m.\u001b[39mlaunch(headless\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheadless)\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m url \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murls:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/playwright/sync_api/_context_manager.py:47\u001b[0m, in \u001b[0;36mPlaywrightContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_own_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loop\u001b[38;5;241m.\u001b[39mis_running():\n\u001b[0;32m---> 47\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m Error(\n\u001b[1;32m     48\u001b[0m \u001b[38;5;250m                \u001b[39m\u001b[38;5;124;03m\"\"\"It looks like you are using Playwright Sync API inside the asyncio loop.\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03mPlease use the Async API instead.\"\"\"\u001b[39;00m\n\u001b[1;32m     50\u001b[0m             )\n\u001b[1;32m     52\u001b[0m         \u001b[38;5;66;03m# Create a new fiber for the protocol dispatcher. It will be pumping events\u001b[39;00m\n\u001b[1;32m     53\u001b[0m         \u001b[38;5;66;03m# until the end of times. We will pass control to that fiber every time we\u001b[39;00m\n\u001b[1;32m     54\u001b[0m         \u001b[38;5;66;03m# block while waiting for a response.\u001b[39;00m\n\u001b[1;32m     55\u001b[0m         \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgreenlet_main\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mError\u001b[0m: It looks like you are using Playwright Sync API inside the asyncio loop.\nPlease use the Async API instead."
     ]
    }
   ],
   "source": [
    "\n",
    "loader = PlaywrightURLLoader([\"https://www.espn.com/nfl/story/_/id/38652877/lions-rb-jahmyr-gibbs-wr-amon-ra-st-brown-return-vs-bucs\"])\n",
    "loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "81769cb4-2ba8-44ea-9fd3-ce6d24be6067",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_documents = TextParser().parse(Blob(data=test_document))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "a859fbf6-9c34-46e0-8dcc-8b1099771752",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 234, which is longer than the specified 100\n",
      "Created a chunk of size 258, which is longer than the specified 100\n",
      "Created a chunk of size 233, which is longer than the specified 100\n",
      "Created a chunk of size 158, which is longer than the specified 100\n",
      "Created a chunk of size 126, which is longer than the specified 100\n",
      "Created a chunk of size 307, which is longer than the specified 100\n",
      "Created a chunk of size 286, which is longer than the specified 100\n",
      "Created a chunk of size 220, which is longer than the specified 100\n"
     ]
    }
   ],
   "source": [
    "text_splitter = CharacterTextSplitter(chunk_size=100, chunk_overlap=0)\n",
    "documents = text_splitter.split_documents(raw_documents)\n",
    "db = FAISS.from_documents(documents, HuggingFaceEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "d468cb09-607d-4d1e-b600-79bebbfad736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gibbs, who did not practice this week, also missed last week's 42-24 victory over the Carolina Panthers with the same injury. With 179 yards and a touchdown with an additional 70 receiving yards in his four appearances, he is Detroit's second-leading rusher.\n"
     ]
    }
   ],
   "source": [
    "query = \"Did Gibbs start this week?\"\n",
    "docs = db.similarity_search(query)\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "50e90fe7-589a-410e-90be-4e2ccf5003c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "ffb904c2-ffde-4652-9dfc-c8039af0eec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:362: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'context': [Document(page_content=\"ALLEN PARK, Mich. -- Detroit Lions running back Jahmyr Gibbs has been ruled out for Sunday's game against the Tampa Bay Buccaneers with a hamstring injury while Pro Bowl receiver Amon-Ra St. Brown (abdomen) is set to make his return.\\n\\nGibbs, who did not practice this week, also missed last week's 42-24 victory over the Carolina Panthers with the same injury. With 179 yards and a touchdown with an additional 70 receiving yards in his four appearances, he is Detroit's second-leading rusher.\\n\\nVeteran running back David Montgomery has carried the load in his absence, with back-to-back games of at least 100 yards rushing. Detroit has rushed for nine touchdowns through the first five games of the season, tying a team record.\\n\\nAlthough expectations are high for Gibbs as the Lions' No. 12 overall selection, running back coach Scottie Montgomery is helping him develop at his own pace.\", metadata={'source': None}),\n",
       "  Document(page_content='\"He\\'s right where I thought he would be, he\\'s right where he should be coming along at at this time,\" Scottie Montgomery said.\\n\\n\"We don\\'t judge players based off of anything else besides achievement. Like there is success and there is expectations and I want people outside the building to put those expectations on him because, guess what, whether we believe it or not it motivates him. It does and that\\'s a really, really good tool.\"\\n\\nMeanwhile, rookie safety Brian Branch, who has an ankle injury, is also set to miss his second consecutive game. The second-round pick out of Alabama was held out of practice for the entire week. With 25 tackles, a pick-six and 4 passes defended, he is Detroit\\'s fourth-leading tackler.\\n\\nRookie tight end Sam LaPorta is questionable with a calf strain that flared up Wednesday, forcing him to miss Thursday\\'s practice. He said it likely stemmed from Sunday\\'s win over Carolina, and he intends to play Sunday.', metadata={'source': None}),\n",
       "  Document(page_content='\"It\\'s football, things happen, we certainly work our bodies pretty hard so I\\'m feeling a lot better today,\" LaPorta said.', metadata={'source': None})],\n",
       " 'question': \"Why didn't Gibbs practice this week?\",\n",
       " 'text': '\\nGibbs did not practice this week due to a hamstring injury.'}"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"Why didn't Gibbs practice this week?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5e4b04-1bab-4923-b0d2-9d0959bb339b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-13.m111",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-13:m111"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
